WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Using TensorFlow backend.
WARNING:tensorflow:From mask_grasp_rcnn.py:1029: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From mask_grasp_rcnn.py:1031: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-10-22 16:59:26.830483: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2020-10-22 16:59:26.830779: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3263100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-22 16:59:26.830810: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-22 16:59:26.832882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-10-22 16:59:26.949938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:26.950657: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x32632c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-10-22 16:59:26.950687: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0
2020-10-22 16:59:26.950876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:26.951429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:00:04.0
2020-10-22 16:59:26.951948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-10-22 16:59:26.953672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-10-22 16:59:26.955444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-10-22 16:59:26.955825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-10-22 16:59:26.957944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-10-22 16:59:26.958800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-10-22 16:59:26.964812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-10-22 16:59:26.964955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:26.965616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:26.966150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-10-22 16:59:26.966220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-10-22 16:59:26.967465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-22 16:59:26.967488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-10-22 16:59:26.967495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-10-22 16:59:26.967654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:26.968219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:26.968805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /content/drive/My Drive/object_vs_background/mrcnn/model.py:1264: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.
Instructions for updating:
box_ind is deprecated, use box_indices instead
2020-10-22 16:59:35.027440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:35.028122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:00:04.0
2020-10-22 16:59:35.028226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-10-22 16:59:35.028257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-10-22 16:59:35.028285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-10-22 16:59:35.028313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-10-22 16:59:35.028337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-10-22 16:59:35.028362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-10-22 16:59:35.028388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-10-22 16:59:35.028483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:35.029162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:35.029703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-10-22 16:59:35.030278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:35.030836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:00:04.0
2020-10-22 16:59:35.030901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-10-22 16:59:35.030930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-10-22 16:59:35.030958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-10-22 16:59:35.030983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-10-22 16:59:35.031005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-10-22 16:59:35.031028: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-10-22 16:59:35.031052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-10-22 16:59:35.031126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:35.031713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:35.032272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-10-22 16:59:35.032316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-10-22 16:59:35.032331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-10-22 16:59:35.032342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-10-22 16:59:35.032455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:35.033049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-10-22 16:59:35.033648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.
Instructions for updating:
reduction_indices is deprecated, use axis instead

Starting at epoch 0. LR=0.002

Checkpoint Path: /content/drive/My Drive/models/grasp_and_mask20201022T1659/mask_rcnn_grasp_and_mask_{epoch:04d}.h5
Selecting layers to train
In model:  rpn_model
grasp_conv1            (TimeDistributed)
grasp_bn1              (TimeDistributed)
grasp_conv2            (TimeDistributed)
grasp_bn2              (TimeDistributed)
grasp_conv3            (TimeDistributed)
grasp_bn3              (TimeDistributed)
grasp_conv4            (TimeDistributed)
grasp_bn4              (TimeDistributed)
grasp_class_conv       (TimeDistributed)
grasp_reg_conv         (TimeDistributed)
grasp_class_bn         (TimeDistributed)
grasp_reg_bn           (TimeDistributed)
grasp_class_raw        (TimeDistributed)
grasp_bbox_pred        (TimeDistributed)
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.

WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.

/tensorflow-1.15.2/python3.6/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.
  UserWarning('Using a generator with `use_multiprocessing=True`'
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Epoch 1/500
2020-10-22 17:01:07.767759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-10-22 17:01:08.046449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
300/300 [==============================] - 251s 838ms/step - loss: 2.1230 - rpn_class_loss: 0.0057 - rpn_bbox_loss: 0.3226 - mrcnn_class_loss: 0.1081 - mrcnn_bbox_loss: 0.3097 - mrcnn_mask_loss: 0.4499 - grasp_loss: 0.9269 - val_loss: 1.7696 - val_rpn_class_loss: 0.0063 - val_rpn_bbox_loss: 0.3115 - val_mrcnn_class_loss: 0.1659 - val_mrcnn_bbox_loss: 0.3359 - val_mrcnn_mask_loss: 0.3774 - val_grasp_loss: 0.8719
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.

Epoch 2/500
300/300 [==============================] - 234s 778ms/step - loss: 2.0592 - rpn_class_loss: 0.0071 - rpn_bbox_loss: 0.3560 - mrcnn_class_loss: 0.1148 - mrcnn_bbox_loss: 0.3026 - mrcnn_mask_loss: 0.4333 - grasp_loss: 0.8453 - val_loss: 1.6537 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.2130 - val_mrcnn_class_loss: 0.0929 - val_mrcnn_bbox_loss: 0.2723 - val_mrcnn_mask_loss: 0.4439 - val_grasp_loss: 0.8239
Epoch 3/500
300/300 [==============================] - 236s 785ms/step - loss: 2.1655 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.3540 - mrcnn_class_loss: 0.1326 - mrcnn_bbox_loss: 0.3159 - mrcnn_mask_loss: 0.4972 - grasp_loss: 0.8599 - val_loss: 2.1888 - val_rpn_class_loss: 0.0079 - val_rpn_bbox_loss: 0.3746 - val_mrcnn_class_loss: 0.1450 - val_mrcnn_bbox_loss: 0.3359 - val_mrcnn_mask_loss: 0.4572 - val_grasp_loss: 0.8267
Epoch 4/500
300/300 [==============================] - 234s 780ms/step - loss: 2.1262 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.3308 - mrcnn_class_loss: 0.1236 - mrcnn_bbox_loss: 0.3292 - mrcnn_mask_loss: 0.4845 - grasp_loss: 0.8515 - val_loss: 2.5176 - val_rpn_class_loss: 0.0065 - val_rpn_bbox_loss: 0.2849 - val_mrcnn_class_loss: 0.1488 - val_mrcnn_bbox_loss: 0.3432 - val_mrcnn_mask_loss: 0.5650 - val_grasp_loss: 0.8173
Epoch 5/500
300/300 [==============================] - 235s 782ms/step - loss: 2.1220 - rpn_class_loss: 0.0067 - rpn_bbox_loss: 0.3346 - mrcnn_class_loss: 0.1287 - mrcnn_bbox_loss: 0.3236 - mrcnn_mask_loss: 0.4805 - grasp_loss: 0.8479 - val_loss: 1.9412 - val_rpn_class_loss: 0.0100 - val_rpn_bbox_loss: 0.3997 - val_mrcnn_class_loss: 0.1111 - val_mrcnn_bbox_loss: 0.3297 - val_mrcnn_mask_loss: 0.4560 - val_grasp_loss: 0.8280
Epoch 6/500
300/300 [==============================] - 233s 776ms/step - loss: 2.1320 - rpn_class_loss: 0.0054 - rpn_bbox_loss: 0.3421 - mrcnn_class_loss: 0.1274 - mrcnn_bbox_loss: 0.3315 - mrcnn_mask_loss: 0.4924 - grasp_loss: 0.8332 - val_loss: 1.7360 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.2817 - val_mrcnn_class_loss: 0.1297 - val_mrcnn_bbox_loss: 0.3273 - val_mrcnn_mask_loss: 0.4027 - val_grasp_loss: 0.8295
Epoch 7/500
300/300 [==============================] - 232s 773ms/step - loss: 1.9868 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.2988 - mrcnn_class_loss: 0.1111 - mrcnn_bbox_loss: 0.3019 - mrcnn_mask_loss: 0.4487 - grasp_loss: 0.8197 - val_loss: 2.3874 - val_rpn_class_loss: 0.0050 - val_rpn_bbox_loss: 0.3507 - val_mrcnn_class_loss: 0.0923 - val_mrcnn_bbox_loss: 0.2938 - val_mrcnn_mask_loss: 0.4209 - val_grasp_loss: 0.8200
Epoch 8/500
300/300 [==============================] - 229s 765ms/step - loss: 2.1391 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.3830 - mrcnn_class_loss: 0.1182 - mrcnn_bbox_loss: 0.3336 - mrcnn_mask_loss: 0.4603 - grasp_loss: 0.8376 - val_loss: 2.2778 - val_rpn_class_loss: 0.0083 - val_rpn_bbox_loss: 0.2990 - val_mrcnn_class_loss: 0.1375 - val_mrcnn_bbox_loss: 0.3193 - val_mrcnn_mask_loss: 0.4264 - val_grasp_loss: 0.7911
Epoch 9/500
300/300 [==============================] - 232s 773ms/step - loss: 2.0791 - rpn_class_loss: 0.0067 - rpn_bbox_loss: 0.3419 - mrcnn_class_loss: 0.1237 - mrcnn_bbox_loss: 0.3377 - mrcnn_mask_loss: 0.4518 - grasp_loss: 0.8174 - val_loss: 2.1278 - val_rpn_class_loss: 0.0062 - val_rpn_bbox_loss: 0.3355 - val_mrcnn_class_loss: 0.0714 - val_mrcnn_bbox_loss: 0.2630 - val_mrcnn_mask_loss: 0.4827 - val_grasp_loss: 0.8245
Epoch 10/500
300/300 [==============================] - 232s 774ms/step - loss: 1.8538 - rpn_class_loss: 0.0040 - rpn_bbox_loss: 0.2937 - mrcnn_class_loss: 0.0909 - mrcnn_bbox_loss: 0.2795 - mrcnn_mask_loss: 0.4144 - grasp_loss: 0.7713 - val_loss: 1.0378 - val_rpn_class_loss: 0.0067 - val_rpn_bbox_loss: 0.3671 - val_mrcnn_class_loss: 0.1498 - val_mrcnn_bbox_loss: 0.3225 - val_mrcnn_mask_loss: 0.4897 - val_grasp_loss: 0.8277
Epoch 11/500
300/300 [==============================] - 233s 776ms/step - loss: 1.9713 - rpn_class_loss: 0.0045 - rpn_bbox_loss: 0.2802 - mrcnn_class_loss: 0.1226 - mrcnn_bbox_loss: 0.3217 - mrcnn_mask_loss: 0.4312 - grasp_loss: 0.8111 - val_loss: 2.0936 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.4561 - val_mrcnn_class_loss: 0.1153 - val_mrcnn_bbox_loss: 0.2946 - val_mrcnn_mask_loss: 0.5540 - val_grasp_loss: 0.8246
Epoch 12/500
300/300 [==============================] - 233s 775ms/step - loss: 2.1146 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.4029 - mrcnn_class_loss: 0.1222 - mrcnn_bbox_loss: 0.3169 - mrcnn_mask_loss: 0.4530 - grasp_loss: 0.8125 - val_loss: 2.5095 - val_rpn_class_loss: 0.0059 - val_rpn_bbox_loss: 0.3390 - val_mrcnn_class_loss: 0.1924 - val_mrcnn_bbox_loss: 0.3774 - val_mrcnn_mask_loss: 0.4763 - val_grasp_loss: 0.8158
Epoch 13/500
300/300 [==============================] - 233s 776ms/step - loss: 2.0698 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.3641 - mrcnn_class_loss: 0.1205 - mrcnn_bbox_loss: 0.3232 - mrcnn_mask_loss: 0.4442 - grasp_loss: 0.8107 - val_loss: 3.5127 - val_rpn_class_loss: 0.0057 - val_rpn_bbox_loss: 0.4392 - val_mrcnn_class_loss: 0.1278 - val_mrcnn_bbox_loss: 0.3515 - val_mrcnn_mask_loss: 0.4535 - val_grasp_loss: 0.8200
Epoch 14/500
300/300 [==============================] - 234s 779ms/step - loss: 1.9026 - rpn_class_loss: 0.0050 - rpn_bbox_loss: 0.2856 - mrcnn_class_loss: 0.0957 - mrcnn_bbox_loss: 0.2804 - mrcnn_mask_loss: 0.4600 - grasp_loss: 0.7760 - val_loss: 1.4047 - val_rpn_class_loss: 0.0054 - val_rpn_bbox_loss: 0.3569 - val_mrcnn_class_loss: 0.1712 - val_mrcnn_bbox_loss: 0.4099 - val_mrcnn_mask_loss: 0.4169 - val_grasp_loss: 0.8448
Epoch 15/500
300/300 [==============================] - 233s 778ms/step - loss: 1.9534 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.2990 - mrcnn_class_loss: 0.1066 - mrcnn_bbox_loss: 0.2876 - mrcnn_mask_loss: 0.4730 - grasp_loss: 0.7813 - val_loss: 2.0829 - val_rpn_class_loss: 0.0070 - val_rpn_bbox_loss: 0.3450 - val_mrcnn_class_loss: 0.1565 - val_mrcnn_bbox_loss: 0.3813 - val_mrcnn_mask_loss: 0.5118 - val_grasp_loss: 0.7818
Epoch 16/500
300/300 [==============================] - 231s 770ms/step - loss: 1.8753 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.3060 - mrcnn_class_loss: 0.0917 - mrcnn_bbox_loss: 0.2563 - mrcnn_mask_loss: 0.4580 - grasp_loss: 0.7574 - val_loss: 2.0240 - val_rpn_class_loss: 0.0075 - val_rpn_bbox_loss: 0.3615 - val_mrcnn_class_loss: 0.1062 - val_mrcnn_bbox_loss: 0.2703 - val_mrcnn_mask_loss: 0.4361 - val_grasp_loss: 0.7987
Epoch 17/500
300/300 [==============================] - 232s 774ms/step - loss: 2.1054 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.3614 - mrcnn_class_loss: 0.1119 - mrcnn_bbox_loss: 0.3210 - mrcnn_mask_loss: 0.5017 - grasp_loss: 0.8031 - val_loss: 1.4094 - val_rpn_class_loss: 0.0078 - val_rpn_bbox_loss: 0.3590 - val_mrcnn_class_loss: 0.1184 - val_mrcnn_bbox_loss: 0.3614 - val_mrcnn_mask_loss: 0.4680 - val_grasp_loss: 0.8306
Epoch 18/500
300/300 [==============================] - 231s 771ms/step - loss: 1.9474 - rpn_class_loss: 0.0065 - rpn_bbox_loss: 0.3091 - mrcnn_class_loss: 0.1167 - mrcnn_bbox_loss: 0.2978 - mrcnn_mask_loss: 0.4414 - grasp_loss: 0.7759 - val_loss: 0.9500 - val_rpn_class_loss: 0.0046 - val_rpn_bbox_loss: 0.3068 - val_mrcnn_class_loss: 0.0974 - val_mrcnn_bbox_loss: 0.3027 - val_mrcnn_mask_loss: 0.3530 - val_grasp_loss: 0.7539
Epoch 19/500
300/300 [==============================] - 234s 779ms/step - loss: 2.1345 - rpn_class_loss: 0.0085 - rpn_bbox_loss: 0.3903 - mrcnn_class_loss: 0.1311 - mrcnn_bbox_loss: 0.3454 - mrcnn_mask_loss: 0.4575 - grasp_loss: 0.8017 - val_loss: 4.0456 - val_rpn_class_loss: 0.0120 - val_rpn_bbox_loss: 0.4125 - val_mrcnn_class_loss: 0.1474 - val_mrcnn_bbox_loss: 0.3561 - val_mrcnn_mask_loss: 0.4402 - val_grasp_loss: 0.8155
Epoch 20/500
300/300 [==============================] - 233s 777ms/step - loss: 1.9427 - rpn_class_loss: 0.0055 - rpn_bbox_loss: 0.2626 - mrcnn_class_loss: 0.1149 - mrcnn_bbox_loss: 0.3100 - mrcnn_mask_loss: 0.4614 - grasp_loss: 0.7883 - val_loss: 2.5467 - val_rpn_class_loss: 0.0105 - val_rpn_bbox_loss: 0.3122 - val_mrcnn_class_loss: 0.1409 - val_mrcnn_bbox_loss: 0.3060 - val_mrcnn_mask_loss: 0.4512 - val_grasp_loss: 0.7788
Epoch 21/500
300/300 [==============================] - 234s 781ms/step - loss: 2.1122 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.3479 - mrcnn_class_loss: 0.1311 - mrcnn_bbox_loss: 0.3440 - mrcnn_mask_loss: 0.4778 - grasp_loss: 0.8054 - val_loss: 1.5653 - val_rpn_class_loss: 0.0076 - val_rpn_bbox_loss: 0.3270 - val_mrcnn_class_loss: 0.1169 - val_mrcnn_bbox_loss: 0.3331 - val_mrcnn_mask_loss: 0.4479 - val_grasp_loss: 0.7837
Epoch 22/500
146/300 [=============>................] - ETA: 1:48 - loss: 2.0750 - rpn_class_loss: 0.0064 - rpn_bbox_loss: 0.3245 - mrcnn_class_loss: 0.1244 - mrcnn_bbox_loss: 0.3377 - mrcnn_mask_loss: 0.4702 - grasp_loss: 0.8118
